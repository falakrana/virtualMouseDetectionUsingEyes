{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aca564-39ef-493b-b5a9-3a7c3b154f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb22324-7556-42db-bb6f-0e3e993a7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam = cv2.VideoCapture(0)\n",
    "# face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "# screen_w, screen_h = pyautogui.size()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize camera and face mesh\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size()\n",
    "\n",
    "# For smooth cursor movement\n",
    "pyautogui.PAUSE = 0\n",
    "pyautogui.FAILSAFE = False\n",
    "smoothing_factor = 0.5\n",
    "prev_x, prev_y = 0, 0\n",
    "\n",
    "# Blink detection variables\n",
    "blink_counter = 0\n",
    "blink_threshold = 3\n",
    "click_performed = False\n",
    "\n",
    "# Calibration variables\n",
    "calibration_points = [(0.25, 0.25), (0.75, 0.25), (0.5, 0.5), (0.25, 0.75), (0.75, 0.75)]\n",
    "calibration_index = 0\n",
    "calibrating = False\n",
    "calibration_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ebac7-9891-4fdf-be76-8068eee36fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     _, frame = cam.read()\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     output = face_mesh.process(rgb_frame)\n",
    "#     landmark_points = output.multi_face_landmarks\n",
    "#     frame_h, frame_w, _ = frame.shape\n",
    "#     if landmark_points:\n",
    "#         landmarks = landmark_points[0].landmark\n",
    "#         for id, landmark in enumerate(landmarks[474:478]):\n",
    "#             x = int(landmark.x * frame_w)\n",
    "#             y = int(landmark.y * frame_h)\n",
    "#             cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "#             if id == 1:\n",
    "#                 screen_x = screen_w * landmark.x\n",
    "#                 screen_y = screen_h * landmark.y\n",
    "#                 pyautogui.moveTo(screen_x, screen_y)\n",
    "#         left = [landmarks[145], landmarks[159]]\n",
    "#         for landmark in left:\n",
    "#             x = int(landmark.x * frame_w)\n",
    "#             y = int(landmark.y * frame_h)\n",
    "#             cv2.circle(frame, (x, y), 3, (0, 255, 255))\n",
    "#         if (left[0].y - left[1].y) < 0.004:\n",
    "#             pyautogui.click()\n",
    "#             pyautogui.sleep(1)\n",
    "#     cv2.imshow('Eye Controlled Mouse', frame)\n",
    "#     cv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    if not _:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    \n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        \n",
    "        # Eye landmarks for cursor control (right eye)\n",
    "        eye_points = landmarks[474:478]\n",
    "        for id, landmark in enumerate(eye_points):\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            \n",
    "            if id == 1:  # Use a specific point for cursor control\n",
    "                # Smooth the cursor movement\n",
    "                screen_x = screen_w * landmark.x\n",
    "                screen_y = screen_h * landmark.y\n",
    "                \n",
    "                if calibrating:\n",
    "                    # During calibration, just show the point\n",
    "                    cv2.putText(frame, \"Calibrating... Look at the dot\", (50, 50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    # Apply smoothing\n",
    "                    smooth_x = prev_x + (screen_x - prev_x) * smoothing_factor\n",
    "                    smooth_y = prev_y + (screen_y - prev_y) * smoothing_factor\n",
    "                    pyautogui.moveTo(smooth_x, smooth_y)\n",
    "                    prev_x, prev_y = smooth_x, smooth_y\n",
    "        \n",
    "        # Blink detection (left eye)\n",
    "        left = [landmarks[145], landmarks[159]]  # top and bottom of left eye\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))\n",
    "        \n",
    "        # Calculate eye opening distance\n",
    "        vertical_dist = abs(left[0].y - left[1].y)\n",
    "        \n",
    "        # Blink detection\n",
    "        if vertical_dist < 0.01:  # Increased threshold for more reliable detection\n",
    "            blink_counter += 1\n",
    "            if blink_counter >= blink_threshold and not click_performed:\n",
    "                pyautogui.click()\n",
    "                click_performed = True\n",
    "                cv2.putText(frame, \"CLICK\", (50, 100), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            blink_counter = 0\n",
    "            click_performed = False\n",
    "        \n",
    "        # Draw eye opening distance\n",
    "        cv2.putText(frame, f\"Eye Open: {vertical_dist:.4f}\", (50, 150), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "    \n",
    "    # Calibration mode\n",
    "    if calibrating:\n",
    "        target_x = int(calibration_points[calibration_index][0] * frame_w)\n",
    "        target_y = int(calibration_points[calibration_index][1] * frame_h)\n",
    "        cv2.circle(frame, (target_x, target_y), 10, (0, 0, 255), -1)\n",
    "        \n",
    "        # Check if user has looked at the point long enough\n",
    "        # (In a real implementation, you'd collect data points here)\n",
    "    \n",
    "    # Display instructions\n",
    "    cv2.putText(frame, \"Press 'c' to calibrate, 'q' to quit\", (10, 20), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        calibrating = not calibrating\n",
    "        if calibrating:\n",
    "            calibration_index = 0\n",
    "            calibration_data = []\n",
    "            print(\"Starting calibration...\")\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b8407-c068-4b6a-bb31-f5e84e4b4457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d987b44-ac09-405d-92f7-96bc121574c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
